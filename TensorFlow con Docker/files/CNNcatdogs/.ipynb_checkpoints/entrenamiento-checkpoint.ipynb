{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ruta de datos de entrenamiento /notebooks/CNNcatdogs/imagenes/train/\n",
      "Now going to read dog files (indiceDeClase: 0)\n",
      "Now going to read cat files (indiceDeClase: 1)\n",
      "Completado el proceso de lecturada de imagenes.\n",
      "Numero de imagenes en el conjunto de entrenamiento:\t800\n",
      "Numero de imagenes en el conjunto de validacion :\t200\n"
     ]
    }
   ],
   "source": [
    "# la fuente del codigo es: https://github.com/sankit1/cv-tricks.com\n",
    "\n",
    "#importa la clase conjuntoDeDatos, esta obtiene las imagenes de entrenamiento por cada subcarpeta o clases de imagenes. \n",
    "import CNN;conjuntoDeDatos\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta\n",
    "import random;os;math;time\n",
    "import numpy as np\n",
    "\n",
    "# instanciar CNN\n",
    "cnncapas = CNN.CNN()\n",
    "\n",
    "# Agregar semilla para que la inicialización aleatoria sea consistente\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "\"\"\" tamanoLotePorIteracion (batch-size) \"\"\"\n",
    "tamanoLotePorIteracion = 32\n",
    "\n",
    "#Preparar la data de entrada\n",
    "#Existen dos calses, perros y gatos.\n",
    "clases = ['dog','cat']\n",
    "numeroClases = len(clases)\n",
    "\n",
    "# leendo las imagenes de entrada\n",
    "# datos de entrenamiento: deberia ser usado el 80% de las imagenes\n",
    "# datos de validacion: deberia ser usado el 20% de las imagenes, estas imagenes deben quedar fuera del conjunto de datos de entrenamiento, este conjunto de datos es necesario para calcular la exactitud del modelo.\n",
    "# datos de prueba, este conjunto de datos es utilizado para probar el modelo, despue de haber entrenado el modelo funciona bien, pero cuando las imagenes son convertidas a un tamaño muy reducido el model puede fallar, a este termino se le conoce como sobre sobreajuste(Overfitting), el sobre ajuste puede ser probocado por el fondo de las imagenes.\n",
    "\n",
    "# tamanoDeDataDeValidacion automaticamente se usara el 20% de todas las imagenes para la validacion.\n",
    "tamanoDeDataDeValidacion = 0.2\n",
    "\n",
    "# El mamaño de las imagenes es de 128 pixeles por 128.\n",
    "tamanoDeImagenes = 128\n",
    "\n",
    "# el numero de canales representa que la imagenen tiene los tres colores RGB\n",
    "numeroDeColoresPorImagen = 3\n",
    "\n",
    "# la ruta de datos de entrenamiento es la carpeta donde se encuentran los conjuntos de imagenes de entrenamiento y validacion\n",
    "rutaDeDatosDeEntrenamiento=os.path.join(os.path.realpath('.'),'imagenes/train/')\n",
    "print(\"ruta de datos de entrenamiento \"+str(rutaDeDatosDeEntrenamiento))\n",
    "# Cargar las imagenes de entrenamiento y validacion con sus etiquetas en memoria usando openCV para ser usadas durante el proceso de entrenamiento.\n",
    "data = conjuntoDeDatos.leerDatosDeEntrenamiento(rutaDeDatosDeEntrenamiento, tamanoDeImagenes, clases, tamanoDeDataDeValidacion)\n",
    "\n",
    "print(\"Completado el proceso de lecturada de imagenes.\")\n",
    "print(\"Numero de imagenes en el conjunto de entrenamiento:\\t{}\".format(len(data.entrenamiento.etiquetas)))\n",
    "print(\"Numero de imagenes en el conjunto de validacion :\\t{}\".format(len(data.validacion.etiquetas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "tensorDeEntrada = tf.placeholder(tf.float32, shape=[None, tamanoDeImagenes,tamanoDeImagenes,numeroDeColoresPorImagen], name='tensorDeEntrada')\n",
    "\n",
    "## Etiquetas\n",
    "tensorDeClases = tf.placeholder(tf.float32, shape=[None, numeroClases], name='tensorDeEntrada')\n",
    "tensorDeClasesAplanado = tf.argmax(tensorDeClases, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Parametros graficos de red\n",
    "# El parametro mas importante en una red convolucional es el tamaño del filtro de cada neurona.  Por ejemplo si entrada de la neurona es una imagen de 32x32x3, esto significa que la imagen tiene una dimension de 32x32 (alto x ancho) pixeles y contiene 3 colores RGB, entonces el filtro significa que se convertiran las imagenes a 5x5x3, es decir 5x5 (alto x ancho) y 3 representa el numero de colores RGB.\n",
    "\n",
    "#Configuracion de la primera capa oculta, el tamaño del filtro es 3 y el numero de filtros es 32\n",
    "\n",
    "capaConvolucional1 = cnncapas.crearCapaConvolucional(tensorDeEntrada=tensorDeEntrada,numeroDeCanales=numeroDeColoresPorImagen,tamanoDelFiltro=3,numeroDeFiltros=32)\n",
    "capaConvolucional2 = cnncapas.crearCapaConvolucional(tensorDeEntrada=capaConvolucional1,numeroDeCanales=32,tamanoDelFiltro=3,numeroDeFiltros=32)\n",
    "capaConvolucional3= cnncapas.crearCapaConvolucional(tensorDeEntrada=capaConvolucional2,numeroDeCanales=32,tamanoDelFiltro=3,numeroDeFiltros=64)\n",
    "capaPlana = cnncapas.crearCapaAplanada(capaConvolucional3)\n",
    "capaTotalmenteConectada1 = cnncapas.crearCapaTotalmenteConectada(tensorDeEntrada=capaPlana,num_inputs=capaPlana.get_shape()[1:4].num_elements(),num_outputs=128,use_relu=True)\n",
    "capaTotalmenteConectada2 = cnncapas.crearCapaTotalmenteConectada(tensorDeEntrada=capaTotalmenteConectada1,num_inputs=128,num_outputs=numeroClases,use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Softmax: Calcula las activaciones softmax, los argumentos de la funcion son:\n",
    "## logits: es un tenson no vacio.  Puede ser uno de los siguientes tipos \"half, float32, float64\"\n",
    "## dim: la dimension softmax puede ser realidad en: el valor default es -1, el cual indica la ultima dimension.\n",
    "## name: es opcional, representa el nombre de la operacion.\n",
    "\n",
    "## retorna: un tensor, tiene el mismo tipo y forma que logits.\n",
    "\n",
    "# la variable ResultadoDeProbabilidadPorClase guarda los valores de la ultima capa (capaTotalmenteConectada2) y obtiene por medio de la funcion softmax los valores de probabilidad en un rango de 0-1\n",
    "prediccionDeProbabilidadPorClase = tf.nn.softmax(capaTotalmenteConectada2,name='prediccionDeProbabilidadPorClase')\n",
    "\n",
    "# la variable ResultadoDeProbabilidadPorClase guarda la probabilidad de cada clase aplanda es decir en un vector.\n",
    "prediccionDeProbabilidadPorClaseAplanada = tf.argmax(prediccionDeProbabilidadPorClase, dimension=1)\n",
    "\n",
    "# tf.Session es una clase para correr operaciones de tensorflow\n",
    "# Un objetivo de una sesion es encapsular el entorno en el cual los objectos (operaciones) son ejecutados y los objectos (Tensores) son evaluados.\n",
    "\n",
    "#inicializar las variables.\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#Entropia cruzada:\n",
    "entropiaCruzada = tf.nn.softmax_cross_entropy_with_logits(logits=capaTotalmenteConectada2,labels=tensorDeClases)\n",
    "perdidaTotalDeErrorEnClasificacion = tf.reduce_mean(entropiaCruzada)\n",
    "optimizador = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(perdidaTotalDeErrorEnClasificacion)\n",
    "correccionDePrediccion = tf.equal(prediccionDeProbabilidadPorClaseAplanada, tensorDeClasesAplanado)\n",
    "exactitudDelModelo = tf.reduce_mean(tf.cast(correccionDePrediccion, tf.float32))\n",
    "\n",
    "#inicializar las variables.\n",
    "tf.summary.FileWriter(\"/tmp/tensorflow/\", session.graph)\n",
    "session.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- FUNCION DE ENTRENAMIENTO  ------------------\n",
      "numero de imagenes para entrenamiento 800\n",
      "-- iteracion # 1 con imagenes # 32\n",
      "siguiente lote, inicio: 0, fin: 32\n",
      "siguiente lote, inicio: 0, fin: 32\n",
      "mostrar epoca 25\n",
      "Training epoca 1 --- Exactitud del entranamiento: 100.0%, Exactitud de validacion: 100.0%,  perida de validacion: 0.559\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parent directory of dogs-cats-model doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-75d8a7f93b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mrecuentoIteraciones\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotalIteraciones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mentrenarModelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalIteraciones\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fin del entrenamiento\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-75d8a7f93b24>\u001b[0m in \u001b[0;36mentrenarModelo\u001b[0;34m(totalIteraciones)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mmostrarProgreso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentrenamiento_imagenesYetiquetasPorEpoca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidacion_imagenesYetiquetasPorEpoca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperdidadDeValidacion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dogs-cats-model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mrecuentoIteraciones\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotalIteraciones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1612\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[1;32m   1613\u001b[0m                   save_path))\n\u001b[0;32m-> 1614\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parent directory of dogs-cats-model doesn't exist, can't save."
     ]
    }
   ],
   "source": [
    "def mostrarProgreso(epoca, feed_dict_train, feed_dict_validate, perdidaDeValidacion):\n",
    "    exactitudDeEntrenamiento = session.run(exactitudDelModelo, feed_dict=feed_dict_train)\n",
    "    exactitudDeValidacion = session.run(exactitudDelModelo, feed_dict=feed_dict_validate)\n",
    "    msg = \"Training epoca {0} --- Exactitud del entranamiento: {1:>6.1%}, Exactitud de validacion: {2:>6.1%},  perida de validacion: {3:.3f}\"\n",
    "    print(msg.format(epoca + 1, exactitudDeEntrenamiento, exactitudDeValidacion, perdidaDeValidacion))\n",
    "\n",
    "recuentoIteraciones = 0\n",
    "\n",
    "\"\"\" batch-size (tamaño del lote por iteracion), cuando se entrena una red no se  alimenta con todo el conjunto de datos, se hace por medio de iteracion y cada iteracion tiene un tamaño, frecuentemente es 16 o 32\"\"\"\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def entrenarModelo(totalIteraciones):\n",
    "    print(\"---------------- FUNCION DE ENTRENAMIENTO  ------------------\")\n",
    "    print(\"numero de imagenes para entrenamiento \"+str(data.entrenamiento.recuento))\n",
    "\n",
    "    global recuentoIteraciones\n",
    "    for iteracion in range(recuentoIteraciones,recuentoIteraciones + totalIteraciones):\n",
    "        print(\"-- iteracion # \"+str(iteracion+1)+\" con imagenes # \"+str(tamanoLotePorIteracion))\n",
    "        entrenamientoPaquete_imagenes, entrenamientoPaquete_etiquetas, entrenamientoPaquete_nombres, entrenamientoPaquete_clases = data.entrenamiento.siguienteLote(tamanoLotePorIteracion)\n",
    "        validacionPaquete_imagenes, validacionPaquete_etiquetas, validacionPaquete_nombres, validacionPaquete_clases = data.validacion.siguienteLote(tamanoLotePorIteracion)\n",
    "\n",
    "        entrenamiento_imagenesYetiquetasPorEpoca = {tensorDeEntrada: entrenamientoPaquete_imagenes,tensorDeClases: entrenamientoPaquete_etiquetas}\n",
    "        validacion_imagenesYetiquetasPorEpoca = {tensorDeEntrada: validacionPaquete_imagenes,tensorDeClases: validacionPaquete_etiquetas}\n",
    "        \n",
    "        session.run(optimizador, feed_dict=entrenamiento_imagenesYetiquetasPorEpoca)\n",
    "\n",
    "        if iteracion % int(data.entrenamiento.recuento/tamanoLotePorIteracion) == 0:\n",
    "            print(\"mostrar epoca \"+str(int(data.entrenamiento.recuento/tamanoLotePorIteracion)))\n",
    "            perdidadDeValidacion = session.run(perdidaTotalDeErrorEnClasificacion, feed_dict=validacion_imagenesYetiquetasPorEpoca)\n",
    "\n",
    "            \"\"\" epoca (epoch) una epoca contiene un conjunto de iteracion que alimentan el modelo \"\"\"\n",
    "            epoca = int(iteracion / int(data.entrenamiento.recuento/tamanoLotePorIteracion))\n",
    "\n",
    "            mostrarProgreso(epoca, entrenamiento_imagenesYetiquetasPorEpoca, validacion_imagenesYetiquetasPorEpoca, perdidadDeValidacion)\n",
    "            saver.save(session, './dogs-cats-model')\n",
    "\n",
    "    recuentoIteraciones += totalIteraciones\n",
    "\n",
    "entrenarModelo(totalIteraciones=3000)\n",
    "print(\"Fin del entrenamiento\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
