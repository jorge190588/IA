{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ruta de datos de entrenamiento /notebooks/CNNcatdogs/imagenes/train/\n",
      "clase dog, indice 0, path /notebooks/CNNcatdogs/imagenes/train/dog.*.jpg, files number 6891, max images 5000\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/build/opencv-SviWsf/opencv-2.4.9.1+dfsg/modules/imgproc/src/imgwarp.cpp:1834: error: (-215) ssize.area() > 0 in function resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31merror\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-728d7d08e63d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ruta de datos de entrenamiento \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrutaDeDatosDeEntrenamiento\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Cargar las imagenes de entrenamiento y validacion con sus etiquetas en memoria usando openCV para ser usadas durante el proceso de entrenamiento.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconjuntoDeDatos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleerDatosDeEntrenamiento\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrutaDeDatosDeEntrenamiento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtamanoDeImagenes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtamanoDeDataDeValidacion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Completado el proceso de lecturada de imagenes.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/CNNcatdogs/conjuntoDeDatos.pyc\u001b[0m in \u001b[0;36mleerDatosDeEntrenamiento\u001b[0;34m(rutaDeDatosDeEntrenamiento, tamanoDeImagenes, clases, tamanoDeDataDeValidacion)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mleerDatosDeEntrenamiento\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrutaDeDatosDeEntrenamiento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtamanoDeImagenes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtamanoDeDataDeValidacion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;32mclass\u001b[0m \u001b[0mDataSets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0mresultadoDeImagenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/CNNcatdogs/conjuntoDeDatos.pyc\u001b[0m in \u001b[0;36mcargarDatosDeEntrenamiento\u001b[0;34m(rutaDeDatos, tamanoDeImagenes, clases)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmaxImages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m \u001b[0;31m# totalImages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clase {}, indice {}, path {}, files number {}, max images {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindiceDeClase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrutaDeDatosDeEntrenamiento\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistaDeArchivos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxImages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0marchivo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistaDeArchivos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mimagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobtenerImagenDesdeRuta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchivo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtamanoDeImagenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/CNNcatdogs/conjuntoDeDatos.pyc\u001b[0m in \u001b[0;36mobtenerImagenDesdeRuta\u001b[0;34m(rutaDeImagen, tamanoDeImagenes)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobtenerImagenDesdeRuta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrutaDeImagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtamanoDeImagenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mimagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrutaDeImagen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mimagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mimagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtamanoDeImagenes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtamanoDeImagenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mimagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /build/opencv-SviWsf/opencv-2.4.9.1+dfsg/modules/imgproc/src/imgwarp.cpp:1834: error: (-215) ssize.area() > 0 in function resize\n"
     ]
    }
   ],
   "source": [
    "# la fuente del codigo es: https://github.com/sankit1/cv-tricks.com\n",
    "\n",
    "#importa la clase conjuntoDeDatos, esta obtiene las imagenes de entrenamiento por cada subcarpeta o clases de imagenes. \n",
    "import CNN\n",
    "import conjuntoDeDatos\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# instanciar CNN\n",
    "cnncapas = CNN.CNN()\n",
    "\n",
    "# Agregar semilla para que la inicialización aleatoria sea consistente\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "\"\"\" tamanoLotePorIteracion (batch-size) \"\"\"\n",
    "tamanoLotePorIteracion = 32\n",
    "\n",
    "#Preparar la data de entrada\n",
    "#Existen dos calses, perros y gatos.\n",
    "clases = ['dog','cat']\n",
    "numeroClases = len(clases)\n",
    "\n",
    "# leendo las imagenes de entrada\n",
    "# datos de entrenamiento: deberia ser usado el 80% de las imagenes\n",
    "# datos de validacion: deberia ser usado el 20% de las imagenes, estas imagenes deben quedar fuera del conjunto de datos de entrenamiento, este conjunto de datos es necesario para calcular la exactitud del modelo.\n",
    "# datos de prueba, este conjunto de datos es utilizado para probar el modelo, despue de haber entrenado el modelo funciona bien, pero cuando las imagenes son convertidas a un tamaño muy reducido el model puede fallar, a este termino se le conoce como sobre sobreajuste(Overfitting), el sobre ajuste puede ser probocado por el fondo de las imagenes.\n",
    "\n",
    "# tamanoDeDataDeValidacion automaticamente se usara el 20% de todas las imagenes para la validacion.\n",
    "tamanoDeDataDeValidacion = 0.2\n",
    "\n",
    "# El mamaño de las imagenes es de 128 pixeles por 128.\n",
    "tamanoDeImagenes = 128\n",
    "\n",
    "# el numero de canales representa que la imagenen tiene los tres colores RGB\n",
    "numeroDeColoresPorImagen = 3\n",
    "\n",
    "# la ruta de datos de entrenamiento es la carpeta donde se encuentran los conjuntos de imagenes de entrenamiento y validacion\n",
    "rutaDeDatosDeEntrenamiento=os.path.join(os.path.realpath('.'),'imagenes/train/')\n",
    "print(\"ruta de datos de entrenamiento \"+str(rutaDeDatosDeEntrenamiento))\n",
    "# Cargar las imagenes de entrenamiento y validacion con sus etiquetas en memoria usando openCV para ser usadas durante el proceso de entrenamiento.\n",
    "data = conjuntoDeDatos.leerDatosDeEntrenamiento(rutaDeDatosDeEntrenamiento, tamanoDeImagenes, clases, tamanoDeDataDeValidacion)\n",
    "\n",
    "print(\"Completado el proceso de lecturada de imagenes.\")\n",
    "print(\"Numero de imagenes en el conjunto de entrenamiento:\\t{}\".format(len(data.entrenamiento.etiquetas)))\n",
    "print(\"Numero de imagenes en el conjunto de validacion :\\t{}\".format(len(data.validacion.etiquetas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "tensorDeEntrada = tf.placeholder(tf.float32, shape=[None, tamanoDeImagenes,tamanoDeImagenes,numeroDeColoresPorImagen], name='tensorDeEntrada')\n",
    "\n",
    "## Etiquetas\n",
    "tensorDeClases = tf.placeholder(tf.float32, shape=[None, numeroClases], name='tensorDeClases')\n",
    "tensorDeClasesAplanado = tf.argmax(tensorDeClases, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Parametros graficos de red\n",
    "# El parametro mas importante en una red convolucional es el tamaño del filtro de cada neurona.  Por ejemplo si entrada de la neurona es una imagen de 32x32x3, esto significa que la imagen tiene una dimension de 32x32 (alto x ancho) pixeles y contiene 3 colores RGB, entonces el filtro significa que se convertiran las imagenes a 5x5x3, es decir 5x5 (alto x ancho) y 3 representa el numero de colores RGB.\n",
    "\n",
    "#Configuracion de la primera capa oculta, el tamaño del filtro es 3 y el numero de filtros es 32\n",
    "\n",
    "#capaConvolucional1 = cnncapas.(tensorDeEntrada,3,3,32)\n",
    "capaConvolucional1 = cnncapas.crearCapaConvolucional(\n",
    "                        tensorDeEntrada=tensorDeEntrada,\n",
    "                        numeroDeCanales=numeroDeColoresPorImagen,\n",
    "                        tamanoDelFiltro=3,\n",
    "                        numeroDeFiltros=32)\n",
    "\n",
    "#capaConvolucional2 = (capaConvolucional1,32,3,32)\n",
    "capaConvolucional2 = cnncapas.crearCapaConvolucional(\n",
    "                        tensorDeEntrada=capaConvolucional1,\n",
    "                        numeroDeCanales=32,\n",
    "                        tamanoDelFiltro=3,\n",
    "                        numeroDeFiltros=32)\n",
    "\n",
    "#capaConvolucional3= cnncapas.(capaConvolucional2,32,3,64)\n",
    "capaConvolucional3= cnncapas.crearCapaConvolucional(\n",
    "                        tensorDeEntrada=capaConvolucional2,\n",
    "                        numeroDeCanales=32,\n",
    "                        tamanoDelFiltro=3,\n",
    "                        numeroDeFiltros=64)\n",
    "\n",
    "capaPlana = cnncapas.crearCapaAplanada(capaConvolucional3)\n",
    "\n",
    "capaTotalmenteConectada1 = cnncapas.crearCapaTotalmenteConectada(\n",
    "                            tensorDeEntrada=capaPlana,\n",
    "                            num_inputs=capaPlana.get_shape()[1:4].num_elements(),\n",
    "                            num_outputs=128,\n",
    "                            use_relu=True)\n",
    "\n",
    "capaTotalmenteConectada2 = cnncapas.crearCapaTotalmenteConectada(\n",
    "                            tensorDeEntrada=capaTotalmenteConectada1,\n",
    "                            num_inputs=128,\n",
    "                            num_outputs=numeroClases,\n",
    "                            use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Softmax: Calcula las activaciones softmax, los argumentos de la funcion son:\n",
    "## logits: es un tenson no vacio.  Puede ser uno de los siguientes tipos \"half, float32, float64\"\n",
    "## dim: la dimension softmax puede ser realidad en: el valor default es -1, el cual indica la ultima dimension.\n",
    "## name: es opcional, representa el nombre de la operacion.\n",
    "\n",
    "## retorna: un tensor, tiene el mismo tipo y forma que logits.\n",
    "\n",
    "# la variable ResultadoDeProbabilidadPorClase guarda los valores de la ultima capa (capaTotalmenteConectada2) y obtiene por medio de la funcion softmax los valores de probabilidad en un rango de 0-1\n",
    "prediccionDeProbabilidadPorClase = tf.nn.softmax(\n",
    "                    capaTotalmenteConectada2,\n",
    "                    name='prediccionDeProbabilidadPorClase')\n",
    "\n",
    "# la variable ResultadoDeProbabilidadPorClase guarda la probabilidad de cada clase aplanda es decir en un vector.\n",
    "prediccionDeProbabilidadPorClaseAplanada = tf.argmax(\n",
    "                    prediccionDeProbabilidadPorClase, \n",
    "                    dimension=1)\n",
    "\n",
    "# tf.Session es una clase para correr operaciones de tensorflow\n",
    "# Un objetivo de una sesion es encapsular el entorno en el cual los objectos (operaciones) son ejecutados y los objectos (Tensores) son evaluados.\n",
    "\n",
    "#inicializar las variables.\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#Entropia cruzada:\n",
    "entropiaCruzada = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=capaTotalmenteConectada2,\n",
    "                    labels=tensorDeClases)\n",
    "\n",
    "perdidaTotalDeErrorEnClasificacion = tf.reduce_mean(entropiaCruzada)\n",
    "\n",
    "optimizador = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(perdidaTotalDeErrorEnClasificacion)\n",
    "\n",
    "correccionDePrediccion = tf.equal(prediccionDeProbabilidadPorClaseAplanada, \n",
    "                                  tensorDeClasesAplanado)\n",
    "\n",
    "exactitudDelModelo = tf.reduce_mean(tf.cast(correccionDePrediccion, tf.float32))\n",
    "\n",
    "#inicializar las variables.\n",
    "tf.summary.FileWriter(\"/tmp/tensorflow/\", session.graph)\n",
    "session.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarProgreso(epoca, feed_dict_train, feed_dict_validate, perdidaDeValidacion):\n",
    "    exactitudDeEntrenamiento = session.run(exactitudDelModelo, feed_dict=feed_dict_train)\n",
    "    exactitudDeValidacion = session.run(exactitudDelModelo, feed_dict=feed_dict_validate)\n",
    "    msg = \"Training epoca {0} --- Exactitud del entranamiento: {1:>6.1%}, Exactitud de validacion: {2:>6.1%},  perida de validacion: {3:.3f}\"\n",
    "    print(msg.format(epoca + 1, exactitudDeEntrenamiento, exactitudDeValidacion, perdidaDeValidacion))\n",
    "\n",
    "recuentoIteraciones = 0\n",
    "\n",
    "\"\"\" batch-size (tamaño del lote por iteracion), cuando se entrena una red no se  alimenta con todo el conjunto de datos, se hace por medio de iteracion y cada iteracion tiene un tamaño, frecuentemente es 16 o 32\"\"\"\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def entrenarModelo(totalIteraciones):\n",
    "    print(\"---------------- FUNCION DE ENTRENAMIENTO  ------------------\")\n",
    "    print(\"numero de imagenes para entrenamiento \"+str(data.entrenamiento.recuento))\n",
    "\n",
    "    global recuentoIteraciones\n",
    "    for iteracion in range(recuentoIteraciones,recuentoIteraciones + totalIteraciones):\n",
    "        print(\"-- iteracion # \"+str(iteracion+1)+\" con imagenes # \"+str(tamanoLotePorIteracion))\n",
    "        \n",
    "        entrenamientoPaquete_imagenes, entrenamientoPaquete_etiquetas, entrenamientoPaquete_nombres, entrenamientoPaquete_clases = data.entrenamiento.siguienteLote(tamanoLotePorIteracion)\n",
    "        validacionPaquete_imagenes, validacionPaquete_etiquetas, validacionPaquete_nombres, validacionPaquete_clases = data.validacion.siguienteLote(tamanoLotePorIteracion)\n",
    "\n",
    "        entrenamiento_imagenesYetiquetasPorEpoca = {tensorDeEntrada: entrenamientoPaquete_imagenes,tensorDeClases: entrenamientoPaquete_etiquetas}\n",
    "        validacion_imagenesYetiquetasPorEpoca = {tensorDeEntrada: validacionPaquete_imagenes,tensorDeClases: validacionPaquete_etiquetas}\n",
    "        \n",
    "        session.run(optimizador, feed_dict=entrenamiento_imagenesYetiquetasPorEpoca)\n",
    "\n",
    "        if iteracion % int(data.entrenamiento.recuento/tamanoLotePorIteracion) == 0:\n",
    "            print(\"mostrar epoca \"+str(int(data.entrenamiento.recuento/tamanoLotePorIteracion)))\n",
    "            perdidadDeValidacion = session.run(perdidaTotalDeErrorEnClasificacion, feed_dict=validacion_imagenesYetiquetasPorEpoca)\n",
    "\n",
    "            \"\"\" epoca (epoch) una epoca contiene un conjunto de iteracion que alimentan el modelo \"\"\"\n",
    "            epoca = int(iteracion / int(data.entrenamiento.recuento/tamanoLotePorIteracion))\n",
    "\n",
    "            mostrarProgreso(epoca, entrenamiento_imagenesYetiquetasPorEpoca, validacion_imagenesYetiquetasPorEpoca, perdidadDeValidacion)\n",
    "            saver.save(session, './model/codigoModificado/dogs-cats-model_20_04_2018_v.1.meta')\n",
    "\n",
    "    recuentoIteraciones += totalIteraciones\n",
    "\n",
    "entrenarModelo(totalIteraciones=3000)\n",
    "print(\"Fin del entrenamiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_compile\n",
    "\n",
    "py_compile.compile(\"conjuntoDeDatos.py\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
