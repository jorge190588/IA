{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ruta de datos de entrenamiento /notebooks/CNNcatdogs/imagenes/train/\n",
      "clase dog, indice 0, path /notebooks/CNNcatdogs/imagenes/train/dog.*.jpg, files number 12243, max images 12243\n",
      "progress, read 999 of 12243\n",
      "progress, read 1999 of 12243\n",
      "progress, read 2999 of 12243\n",
      "progress, read 3999 of 12243\n",
      "progress, read 4999 of 12243\n",
      "progress, read 5999 of 12243\n",
      "progress, read 6999 of 12243\n",
      "progress, read 7999 of 12243\n",
      "progress, read 8999 of 12243\n",
      "progress, read 9999 of 12243\n",
      "progress, read 10999 of 12243\n",
      "progress, read 11999 of 12243\n",
      "clase cat, indice 1, path /notebooks/CNNcatdogs/imagenes/train/cat.*.jpg, files number 12500, max images 12500\n",
      "progress, read 999 of 12500\n",
      "progress, read 1999 of 12500\n",
      "progress, read 2999 of 12500\n",
      "progress, read 3999 of 12500\n",
      "progress, read 4999 of 12500\n",
      "progress, read 5999 of 12500\n",
      "progress, read 6999 of 12500\n",
      "progress, read 7999 of 12500\n",
      "progress, read 8999 of 12500\n",
      "progress, read 9999 of 12500\n",
      "progress, read 10999 of 12500\n",
      "progress, read 11999 of 12500\n",
      "End to get images\n",
      "Completado el proceso de lecturada de imagenes.\n",
      "Numero de imagenes en el conjunto de entrenamiento:\t19794\n",
      "Numero de imagenes en el conjunto de validacion :\t4948\n"
     ]
    }
   ],
   "source": [
    "# la fuente del codigo es: https://github.com/sankit1/cv-tricks.com\n",
    "\n",
    "#importa la clase conjuntoDeDatos, esta obtiene las imagenes de entrenamiento por cada subcarpeta o clases de imagenes. \n",
    "import CNN\n",
    "import conjuntoDeDatos\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# instanciar CNN\n",
    "cnncapas = CNN.CNN()\n",
    "\n",
    "# Agregar semilla para que la inicialización aleatoria sea consistente\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "\"\"\" tamanoLotePorIteracion (batch-size) \"\"\"\n",
    "tamanoLotePorIteracion = 32\n",
    "\n",
    "#Preparar la data de entrada\n",
    "#Existen dos calses, perros y gatos.\n",
    "clases = ['dog','cat']\n",
    "numeroClases = len(clases)\n",
    "\n",
    "# leendo las imagenes de entrada\n",
    "# datos de entrenamiento: deberia ser usado el 80% de las imagenes\n",
    "# datos de validacion: deberia ser usado el 20% de las imagenes, estas imagenes deben quedar fuera del conjunto de datos de entrenamiento, este conjunto de datos es necesario para calcular la exactitud del modelo.\n",
    "# datos de prueba, este conjunto de datos es utilizado para probar el modelo, despue de haber entrenado el modelo funciona bien, pero cuando las imagenes son convertidas a un tamaño muy reducido el model puede fallar, a este termino se le conoce como sobre sobreajuste(Overfitting), el sobre ajuste puede ser probocado por el fondo de las imagenes.\n",
    "\n",
    "# tamanoDeDataDeValidacion automaticamente se usara el 20% de todas las imagenes para la validacion.\n",
    "tamanoDeDataDeValidacion = 0.2\n",
    "\n",
    "# El mamaño de las imagenes es de 128 pixeles por 128.\n",
    "tamanoDeImagenes = 128\n",
    "\n",
    "# el numero de canales representa que la imagenen tiene los tres colores RGB\n",
    "numeroDeColoresPorImagen = 3\n",
    "\n",
    "# la ruta de datos de entrenamiento es la carpeta donde se encuentran los conjuntos de imagenes de entrenamiento y validacion\n",
    "rutaDeDatosDeEntrenamiento=os.path.join(os.path.realpath('.'),'imagenes/train/')\n",
    "print(\"ruta de datos de entrenamiento \"+str(rutaDeDatosDeEntrenamiento))\n",
    "# Cargar las imagenes de entrenamiento y validacion con sus etiquetas en memoria usando openCV para ser usadas durante el proceso de entrenamiento.\n",
    "data = conjuntoDeDatos.leerDatosDeEntrenamiento(rutaDeDatosDeEntrenamiento, tamanoDeImagenes, clases, tamanoDeDataDeValidacion)\n",
    "\n",
    "print(\"Completado el proceso de lecturada de imagenes.\")\n",
    "print(\"Numero de imagenes en el conjunto de entrenamiento:\\t{}\".format(len(data.entrenamiento.etiquetas)))\n",
    "print(\"Numero de imagenes en el conjunto de validacion :\\t{}\".format(len(data.validacion.etiquetas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "tensorDeEntrada = tf.placeholder(tf.float32, shape=[None, tamanoDeImagenes,tamanoDeImagenes,numeroDeColoresPorImagen], name='tensorDeEntrada')\n",
    "\n",
    "## Etiquetas\n",
    "tensorDeClases = tf.placeholder(tf.float32, shape=[None, numeroClases], name='tensorDeClases')\n",
    "tensorDeClasesAplanado = tf.argmax(tensorDeClases, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Parametros graficos de red\n",
    "# El parametro mas importante en una red convolucional es el tamaño del filtro de cada neurona.  Por ejemplo si entrada de la neurona es una imagen de 32x32x3, esto significa que la imagen tiene una dimension de 32x32 (alto x ancho) pixeles y contiene 3 colores RGB, entonces el filtro significa que se convertiran las imagenes a 5x5x3, es decir 5x5 (alto x ancho) y 3 representa el numero de colores RGB.\n",
    "\n",
    "#Configuracion de la primera capa oculta, el tamaño del filtro es 3 y el numero de filtros es 32\n",
    "\n",
    "#capaConvolucional1 = cnncapas.(tensorDeEntrada,3,3,32)\n",
    "capaConvolucional1 = cnncapas.crearCapaConvolucional(\n",
    "                        tensorDeEntrada=tensorDeEntrada,\n",
    "                        numeroDeCanales=numeroDeColoresPorImagen,\n",
    "                        tamanoDelFiltro=3,\n",
    "                        numeroDeFiltros=32)\n",
    "\n",
    "#capaConvolucional2 = (capaConvolucional1,32,3,32)\n",
    "capaConvolucional2 = cnncapas.crearCapaConvolucional(\n",
    "                        tensorDeEntrada=capaConvolucional1,\n",
    "                        numeroDeCanales=32,\n",
    "                        tamanoDelFiltro=3,\n",
    "                        numeroDeFiltros=32)\n",
    "\n",
    "#capaConvolucional3= cnncapas.(capaConvolucional2,32,3,64)\n",
    "capaConvolucional3= cnncapas.crearCapaConvolucional(\n",
    "                        tensorDeEntrada=capaConvolucional2,\n",
    "                        numeroDeCanales=32,\n",
    "                        tamanoDelFiltro=3,\n",
    "                        numeroDeFiltros=64)\n",
    "\n",
    "capaPlana = cnncapas.crearCapaAplanada(capaConvolucional3)\n",
    "\n",
    "capaTotalmenteConectada1 = cnncapas.crearCapaTotalmenteConectada(\n",
    "                            tensorDeEntrada=capaPlana,\n",
    "                            num_inputs=capaPlana.get_shape()[1:4].num_elements(),\n",
    "                            num_outputs=128,\n",
    "                            use_relu=True)\n",
    "\n",
    "capaTotalmenteConectada2 = cnncapas.crearCapaTotalmenteConectada(\n",
    "                            tensorDeEntrada=capaTotalmenteConectada1,\n",
    "                            num_inputs=128,\n",
    "                            num_outputs=numeroClases,\n",
    "                            use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Softmax: Calcula las activaciones softmax, los argumentos de la funcion son:\n",
    "## logits: es un tenson no vacio.  Puede ser uno de los siguientes tipos \"half, float32, float64\"\n",
    "## dim: la dimension softmax puede ser realidad en: el valor default es -1, el cual indica la ultima dimension.\n",
    "## name: es opcional, representa el nombre de la operacion.\n",
    "\n",
    "## retorna: un tensor, tiene el mismo tipo y forma que logits.\n",
    "\n",
    "# la variable ResultadoDeProbabilidadPorClase guarda los valores de la ultima capa (capaTotalmenteConectada2) y obtiene por medio de la funcion softmax los valores de probabilidad en un rango de 0-1\n",
    "prediccionDeProbabilidadPorClase = tf.nn.softmax(\n",
    "                    capaTotalmenteConectada2,\n",
    "                    name='prediccionDeProbabilidadPorClase')\n",
    "\n",
    "# la variable ResultadoDeProbabilidadPorClase guarda la probabilidad de cada clase aplanda es decir en un vector.\n",
    "prediccionDeProbabilidadPorClaseAplanada = tf.argmax(\n",
    "                    prediccionDeProbabilidadPorClase, \n",
    "                    dimension=1)\n",
    "\n",
    "# tf.Session es una clase para correr operaciones de tensorflow\n",
    "# Un objetivo de una sesion es encapsular el entorno en el cual los objectos (operaciones) son ejecutados y los objectos (Tensores) son evaluados.\n",
    "\n",
    "#inicializar las variables.\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#Entropia cruzada:\n",
    "entropiaCruzada = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=capaTotalmenteConectada2,\n",
    "                    labels=tensorDeClases)\n",
    "\n",
    "perdidaTotalDeErrorEnClasificacion = tf.reduce_mean(entropiaCruzada)\n",
    "\n",
    "optimizador = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(perdidaTotalDeErrorEnClasificacion)\n",
    "\n",
    "correccionDePrediccion = tf.equal(prediccionDeProbabilidadPorClaseAplanada, \n",
    "                                  tensorDeClasesAplanado)\n",
    "\n",
    "exactitudDelModelo = tf.reduce_mean(tf.cast(correccionDePrediccion, tf.float32))\n",
    "\n",
    "#inicializar las variables.\n",
    "tf.summary.FileWriter(\"/tmp/tensorflow/\", session.graph)\n",
    "session.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- FUNCION DE ENTRENAMIENTO  ------------------\n",
      "numero de imagenes para entrenamiento 19794\n",
      "mostrar epoca 618\n",
      "Training epoca 1 --- Exactitud del entranamiento:  53.1%, Exactitud de validacion:  59.4%,  perida de validacion: 0.691\n",
      "-- iteracion # 100 con imagenes # 32\n",
      "-- iteracion # 200 con imagenes # 32\n",
      "-- iteracion # 300 con imagenes # 32\n",
      "-- iteracion # 400 con imagenes # 32\n",
      "-- iteracion # 500 con imagenes # 32\n",
      "-- iteracion # 600 con imagenes # 32\n",
      "mostrar epoca 618\n",
      "Training epoca 2 --- Exactitud del entranamiento:  59.4%, Exactitud de validacion:  65.6%,  perida de validacion: 0.645\n",
      "-- iteracion # 700 con imagenes # 32\n",
      "-- iteracion # 800 con imagenes # 32\n",
      "-- iteracion # 900 con imagenes # 32\n",
      "-- iteracion # 1000 con imagenes # 32\n",
      "-- iteracion # 1100 con imagenes # 32\n",
      "-- iteracion # 1200 con imagenes # 32\n",
      "mostrar epoca 618\n",
      "Training epoca 3 --- Exactitud del entranamiento:  59.4%, Exactitud de validacion:  81.2%,  perida de validacion: 0.408\n",
      "-- iteracion # 1300 con imagenes # 32\n",
      "-- iteracion # 1400 con imagenes # 32\n",
      "-- iteracion # 1500 con imagenes # 32\n",
      "-- iteracion # 1600 con imagenes # 32\n",
      "-- iteracion # 1700 con imagenes # 32\n",
      "-- iteracion # 1800 con imagenes # 32\n",
      "mostrar epoca 618\n",
      "Training epoca 4 --- Exactitud del entranamiento:  56.2%, Exactitud de validacion:  78.1%,  perida de validacion: 0.526\n",
      "-- iteracion # 1900 con imagenes # 32\n",
      "-- iteracion # 2000 con imagenes # 32\n",
      "-- iteracion # 2100 con imagenes # 32\n",
      "-- iteracion # 2200 con imagenes # 32\n",
      "-- iteracion # 2300 con imagenes # 32\n",
      "-- iteracion # 2400 con imagenes # 32\n",
      "mostrar epoca 618\n",
      "Training epoca 5 --- Exactitud del entranamiento:  68.8%, Exactitud de validacion:  84.4%,  perida de validacion: 0.395\n",
      "-- iteracion # 2500 con imagenes # 32\n",
      "-- iteracion # 2600 con imagenes # 32\n",
      "-- iteracion # 2700 con imagenes # 32\n",
      "-- iteracion # 2800 con imagenes # 32\n",
      "-- iteracion # 2900 con imagenes # 32\n",
      "-- iteracion # 3000 con imagenes # 32\n",
      "mostrar epoca 618\n",
      "Training epoca 6 --- Exactitud del entranamiento:  71.9%, Exactitud de validacion:  84.4%,  perida de validacion: 0.438\n",
      "-- iteracion # 3100 con imagenes # 32\n",
      "-- iteracion # 3200 con imagenes # 32\n",
      "-- iteracion # 3300 con imagenes # 32\n",
      "-- iteracion # 3400 con imagenes # 32\n",
      "-- iteracion # 3500 con imagenes # 32\n",
      "-- iteracion # 3600 con imagenes # 32\n",
      "-- iteracion # 3700 con imagenes # 32\n",
      "mostrar epoca 618\n",
      "Training epoca 7 --- Exactitud del entranamiento:  78.1%, Exactitud de validacion:  78.1%,  perida de validacion: 0.474\n",
      "-- iteracion # 3800 con imagenes # 32\n",
      "-- iteracion # 3900 con imagenes # 32\n",
      "-- iteracion # 4000 con imagenes # 32\n",
      "Fin del entrenamiento\n"
     ]
    }
   ],
   "source": [
    "def mostrarProgreso(epoca, entrenamiento_imagenesYetiquetasPorEpoca, validacion_imagenesYetiquetasPorEpoca, perdidaDeValidacion):\n",
    "    exactitudDeEntrenamiento = session.run(exactitudDelModelo, feed_dict=entrenamiento_imagenesYetiquetasPorEpoca)\n",
    "    exactitudDeValidacion = session.run(exactitudDelModelo, feed_dict=validacion_imagenesYetiquetasPorEpoca)\n",
    "    msg = \"Training epoca {0} --- Exactitud del entranamiento: {1:>6.1%}, Exactitud de validacion: {2:>6.1%},  perida de validacion: {3:.3f}\"\n",
    "    print(msg.format(epoca + 1, exactitudDeEntrenamiento, exactitudDeValidacion, perdidaDeValidacion))\n",
    "\n",
    "recuentoIteraciones = 0\n",
    "\n",
    "\"\"\" batch-size (tamaño del lote por iteracion), cuando se entrena una red no se  alimenta con todo el conjunto de datos, se hace por medio de iteracion y cada iteracion tiene un tamaño, frecuentemente es 16 o 32\"\"\"\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def entrenarModelo(totalIteraciones):\n",
    "    print(\"---------------- FUNCION DE ENTRENAMIENTO  ------------------\")\n",
    "    print(\"numero de imagenes para entrenamiento \"+str(data.entrenamiento.recuento))\n",
    "\n",
    "    global recuentoIteraciones\n",
    "    for iteracion in range(recuentoIteraciones,recuentoIteraciones + totalIteraciones):\n",
    "        if((iteracion+1) % 100 == 0):\n",
    "            print(\"-- iteracion # \"+str(iteracion+1)+\" con imagenes # \"+str(tamanoLotePorIteracion))\n",
    "        \n",
    "        entrenamientoPaquete_imagenes, entrenamientoPaquete_etiquetas, entrenamientoPaquete_nombres, entrenamientoPaquete_clases = data.entrenamiento.siguienteLote(tamanoLotePorIteracion)\n",
    "        validacionPaquete_imagenes, validacionPaquete_etiquetas, validacionPaquete_nombres, validacionPaquete_clases = data.validacion.siguienteLote(tamanoLotePorIteracion)\n",
    "\n",
    "        entrenamiento_imagenesYetiquetasPorEpoca = {tensorDeEntrada: entrenamientoPaquete_imagenes,tensorDeClases: entrenamientoPaquete_etiquetas}\n",
    "        validacion_imagenesYetiquetasPorEpoca = {tensorDeEntrada: validacionPaquete_imagenes,tensorDeClases: validacionPaquete_etiquetas}\n",
    "        \n",
    "        session.run(optimizador, feed_dict=entrenamiento_imagenesYetiquetasPorEpoca)\n",
    "\n",
    "        if iteracion % int(data.entrenamiento.recuento/tamanoLotePorIteracion) == 0:\n",
    "            print(\"mostrar epoca \"+str(int(data.entrenamiento.recuento/tamanoLotePorIteracion)))\n",
    "            perdidadDeValidacion = session.run(perdidaTotalDeErrorEnClasificacion, feed_dict=validacion_imagenesYetiquetasPorEpoca)\n",
    "\n",
    "            \"\"\" epoca (epoch) una epoca contiene un conjunto de iteracion que alimentan el modelo \"\"\"\n",
    "            epoca = int(iteracion / int(data.entrenamiento.recuento/tamanoLotePorIteracion))\n",
    "\n",
    "            mostrarProgreso(epoca, entrenamiento_imagenesYetiquetasPorEpoca, validacion_imagenesYetiquetasPorEpoca, perdidadDeValidacion)\n",
    "            saver.save(session, './model/codigoModificado/dogs-cats-model_20_04_2018_v.1.meta')\n",
    "\n",
    "    recuentoIteraciones += totalIteraciones\n",
    "\n",
    "entrenarModelo(totalIteraciones=4000)\n",
    "print(\"Fin del entrenamiento\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
