{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to read training images\n",
      "Now going to read dogs files (Index: 0)\n",
      "Now going to read cats files (Index: 1)\n",
      "Completado el proceso de lecturada de imagenes.\n",
      "Numero de imagenes en el conjunto de entrenamiento:\t16\n",
      "Numero de imagenes en el conjunto de validacion :\t4\n"
     ]
    }
   ],
   "source": [
    "# la fuente del codigo es: https://github.com/sankit1/cv-tricks.com\n",
    "\n",
    "#importa la clase conjuntoDeDatos, esta obtiene las imagenes de entrenamiento por cada subcarpeta o clases de imagenes. \n",
    "import conjuntoDeDatos\n",
    "# importa lar libreria de tensorflow.\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Adding Seed so that random initialization is consistent\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "\"\"\" tamanoLotePorIteracion (batch-size) \"\"\"\n",
    "tamanoLotePorIteracion = 32\n",
    "\n",
    "#Preparar la data de entrada\n",
    "#Existen dos calses, perros y gatos.\n",
    "clases = ['dogs','cats']\n",
    "numeroClases = len(clases)\n",
    "\n",
    "# leendo las imagenes de entrada\n",
    "# datos de entrenamiento: deberia ser usado el 80% de las imagenes\n",
    "# datos de validacion: deberia ser usado el 20% de las imagenes, estas imagenes deben quedar fuera del conjunto de datos de entrenamiento, este conjunto de datos es necesario para calcular la exactitud del modelo.\n",
    "# datos de prueba, este conjunto de datos es utilizado para probar el modelo, despue de haber entrenado el modelo funciona bien, pero cuando las imagenes son convertidas a un tamaño muy reducido el model puede fallar, a este termino se le conoce como sobre sobreajuste(Overfitting), el sobre ajuste puede ser probocado por el fondo de las imagenes.\n",
    "\n",
    "# tamanoDeDataDeValidacion automaticamente se usara el 20% de todas las imagenes para la validacion.\n",
    "tamanoDeDataDeValidacion = 0.2\n",
    "\n",
    "# El mamaño de las imagenes es de 128 pixeles por 128.\n",
    "tamanoDeImagenes = 128\n",
    "\n",
    "# el numero de canales representa que la imagenen tiene los tres colores RGB\n",
    "numeroDeColoresPorImagen = 3\n",
    "\n",
    "# la ruta de datos de entrenamiento es la carpeta donde se encuentran los conjuntos de imagenes de entrenamiento y validacion\n",
    "rutaDeDatosDeEntrenamiento='datosDeEntrenamiento'\n",
    "\n",
    "# Cargar las imagenes de entrenamiento y validacion con sus etiquetas en memoria usando openCV para ser usadas durante el proceso de entrenamiento.\n",
    "data = conjuntoDeDatos.leerDatosDeEntrenamiento(rutaDeDatosDeEntrenamiento, tamanoDeImagenes, clases, validation_size=tamanoDeDataDeValidacion)\n",
    "\n",
    "print(\"Completado el proceso de lecturada de imagenes.\")\n",
    "print(\"Numero de imagenes en el conjunto de entrenamiento:\\t{}\".format(len(data.train.labels)))\n",
    "print(\"Numero de imagenes en el conjunto de validacion :\\t{}\".format(len(data.valid.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "session = tf.Session()\n",
    "x = tf.placeholder(tf.float32, shape=[None, tamanoDeImagenes,tamanoDeImagenes,numeroDeColoresPorImagen], name='x')\n",
    "\n",
    "## Etiquetas\n",
    "tensorDeClases = tf.placeholder(tf.float32, shape=[None, numeroClases], name='tensorDeClases')\n",
    "tensorDeClasesAplanado = tf.argmax(tensorDeClases, dimension=1)\n",
    "\n",
    "##Parametros graficos de red\n",
    "# El parametro mas importante en una red convolucional es el tamaño del filtro de cada neurona.  Por ejemplo si entrada de la neurona es una imagen de 32x32x3, esto significa que la imagen tiene una dimension de 32x32 (alto x ancho) pixeles y contiene 3 colores RGB, entonces el filtro significa que se convertiran las imagenes a 5x5x3, es decir 5x5 (alto x ancho) y 3 representa el numero de colores RGB.\n",
    "\n",
    "#Configuracion de la primera capa oculta, el tamaño del filtro es 3 y el numero de filtros es 32\n",
    "#filter_size_conv1\n",
    "#num_filters_conv1\n",
    "tamanoFiltroCapaConvolucional1 = 3\n",
    "numeroFiltrosCapaConvolucional1 = 32\n",
    "\n",
    "tamanoFiltroCapaConvolucional2 = 3\n",
    "numeroFiltrosCapaConvolucional2 = 32\n",
    "\n",
    "tamanoFiltroCapaConvolucional3 = 3\n",
    "numeroFiltrosCapaConvolucional3 = 64\n",
    "\n",
    "tamanoDeCapaTotalmenteConectada = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# crear pesos\n",
    "def crearPesos(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "#crear sesgos\n",
    "def crearSesgos(size):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[size]))\n",
    "\n",
    "#funcion para crear un capa convolucional.\n",
    "def crearCapaConvolucional(input,num_input_channels, conv_filter_size,num_filters):\n",
    "\n",
    "    ## We shall define the weights that will be trained using create_weights function.\n",
    "    ## Debemos definir los pesos que seran entrenables usango la funcion crearPesos\n",
    "    pesos = crearPesos(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
    "\n",
    "    ## We create biases using the create_biases function. These are also trained.\n",
    "    ## creamos los sesgos usanto la funcion crearSesgos. Estos son tambien entrenados\n",
    "    sesgos = crearSesgos(num_filters)\n",
    "\n",
    "    ## Creando la capa convolucional\n",
    "    capa = tf.nn.conv2d(input=input,\n",
    "                     filter=pesos,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding='SAME')\n",
    "\n",
    "    #Agregar los sesgos a la capa.\n",
    "    capa += sesgos\n",
    "\n",
    "    ## We shall be using max-pooling. see more information on https://www.quora.com/What-is-max-pooling-in-convolutional-neural-networks\n",
    "    # Estaremos usando el metodo cnn.max-pooling de tensorflow. El algoritmo realiza el maximo agrupamiento en la entrada\n",
    "    ##Los parametros de cnn.max_pool son:\n",
    "    # value =  Un tendor de 4 dimension con formato especificado por data_format.\n",
    "    # ksize =  Un tensor de tipo entero (int) de 1 dimension con 4 elementos.  \n",
    "    ##         Representan el tama;o de la ventana para cada dimension del tensor de entrada.\n",
    "    # strides= Strides significa pasos. Es un tensor de tipo entero (int) de 1 dimension con 4 elementos.\n",
    "    ##         El paso de la ventana deslizante para cada dimension del tensor de entrada.\n",
    "    # padding= Es el relleno.  Es un texto, ya sea SAME o VALID.   Existe un algoritmo para el relleno (padding)\n",
    "    # ver documentacion de tf.cnn.max_pooling\n",
    "    capa = tf.nn.max_pool(value=capa,\n",
    "                            ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1],\n",
    "                            padding='SAME')\n",
    "\n",
    "    ## Output of pooling is fed to Relu which is the activation function for us.\n",
    "    capa = tf.nn.relu(capa)\n",
    "\n",
    "    # retornar un tensor con el formato especificado en data_format.  Es un tensor resultante con el maximo de agrupamiento.\n",
    "    return capa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "def crearCapaAplanada(capaNoAplanada):\n",
    "    #We know that the shape of the layer will be [batch_size img_size img_size num_channels]\n",
    "    #sabemos que la forma de una capa podria ser [tamanoPaquete tamanoImagene tamanoImagen numeroCanales]\n",
    "\n",
    "    # pero conseguiremos esto desde una capa previa\n",
    "    # But let's get it from the previous layer.\n",
    "    formaDeLaCapa = capaNoAplanada.get_shape()\n",
    "\n",
    "    ## El numero de caracteristica podria ser altoImagen * anchoImagen * numeroCanales.  \n",
    "    ## Pero nosotros deberiamos calcularlo esto en lugar de codificarlo con a la fuerza o forzado.\n",
    "    numeroDeCaracteristicas = formaDeLaCapa[1:4].num_elements()\n",
    "\n",
    "    ## ahora, aplanaremos la capa, asi que tendremos que remodelar (reshape) la cantidad de caracteristicas (num_features)\n",
    "    capaAplanada = tf.reshape(capaNoAplanada, [-1, numeroDeCaracteristicas])\n",
    "\n",
    "    #retornar la capa aplanda.\n",
    "    return capaAplanada\n",
    "\n",
    "def crearCapaTotalmenteConectada(input,num_inputs,num_outputs,use_relu=True):\n",
    "    #vamos a definir los pesos y sesgos entrenables\n",
    "    pesos = crearPesos(shape=[num_inputs, num_outputs])\n",
    "    sesgos = crearSesgos(num_outputs)\n",
    "\n",
    "    # Fully connected layer takes input x and produces wx+b.Since, these are matrices, we use matmul function in Tensorflow\n",
    "    capaTotalmenteConectada = tf.matmul(input, pesos) + sesgos\n",
    "    if use_relu:\n",
    "        capaTotalmenteConectada = tf.nn.relu(capaTotalmenteConectada)\n",
    "\n",
    "    return capaTotalmenteConectada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crear capa totalmente concetada 1, tamanoDeCapaTotalmenteConectada= 128, numeroClases= 2\n",
      "crear capa totalmente concetada 2, tamanoDeCapaTotalmenteConectada= 128, numeroClases= 2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<font color='red'>**Jupyter Kernel terminated:**</font> This might be caused by running out of memory or hitting a bug in some library (e.g., forking too many processes, trying to access invalid memory, etc.). Consider restarting or upgrading your project or running the relevant code directly in a terminal to track down the cause, as [explained here](https://github.com/sagemathinc/cocalc/wiki/KernelTerminated)."
      ]
     },
     "execution_count": 12,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capaConvolucional1 = crearCapaConvolucional(input=x,\n",
    "               num_input_channels=numeroDeColoresPorImagen,\n",
    "               conv_filter_size=tamanoFiltroCapaConvolucional1,\n",
    "               num_filters=numeroFiltrosCapaConvolucional1)\n",
    "\n",
    "capaConvolucional2 = crearCapaConvolucional(input=capaConvolucional1,\n",
    "               num_input_channels=numeroFiltrosCapaConvolucional1,\n",
    "               conv_filter_size=tamanoFiltroCapaConvolucional2,\n",
    "               num_filters=numeroFiltrosCapaConvolucional2)\n",
    "\n",
    "capaConvolucional3= crearCapaConvolucional(input=capaConvolucional1,\n",
    "               num_input_channels=numeroFiltrosCapaConvolucional2,\n",
    "               conv_filter_size=tamanoFiltroCapaConvolucional3,\n",
    "               num_filters=numeroFiltrosCapaConvolucional3)\n",
    "\n",
    "capaPlana = crearCapaAplanada(capaConvolucional3)\n",
    "\n",
    "capaTotalmenteConectada1 = crearCapaTotalmenteConectada(input=capaPlana,\n",
    "                     num_inputs=capaPlana.get_shape()[1:4].num_elements(),\n",
    "                     num_outputs=tamanoDeCapaTotalmenteConectada,\n",
    "                     use_relu=True)\n",
    "\n",
    "print(\"crear capa totalmente concetada 1, tamanoDeCapaTotalmenteConectada= \"+str(tamanoDeCapaTotalmenteConectada)+\", numeroClases= \"+str(numeroClases))\n",
    "\n",
    "capaTotalmenteConectada2 = crearCapaTotalmenteConectada(input=capaTotalmenteConectada1,\n",
    "                     num_inputs=tamanoDeCapaTotalmenteConectada,\n",
    "                     num_outputs=numeroClases,\n",
    "                     use_relu=False)\n",
    "\n",
    "print(\"crear capa totalmente concetada 2, tamanoDeCapaTotalmenteConectada= \"+str(tamanoDeCapaTotalmenteConectada)+\", numeroClases= \"+str(numeroClases))\n",
    "\n",
    "#Softmax: Calcula las activaciones softmax, los argumentos de la funcion son:\n",
    "## logits: es un tenson no vacio.  Puede ser uno de los siguientes tipos \"half, float32, float64\"\n",
    "## dim: la dimension softmax puede ser realidad en: el valor default es -1, el cual indica la ultima dimension.\n",
    "## name: es opcional, representa el nombre de la operacion.\n",
    "\n",
    "## retorna: un tensor, tiene el mismo tipo y forma que logits.\n",
    "\n",
    "# la variable ResultadoDeProbabilidadPorClase guarda los valores de la ultima capa (capaTotalmenteConectada2) y obtiene por medio de la funcion softmax los valores de probabilidad en un rango de 0-1\n",
    "prediccionDeProbabilidadPorClase = tf.nn.softmax(capaTotalmenteConectada2,name='prediccionDeProbabilidadPorClase')\n",
    "\n",
    "# la variable ResultadoDeProbabilidadPorClase guarda la probabilidad de cada clase aplanda es decir en un vector.\n",
    "prediccionDeProbabilidadPorClaseAplanada = tf.argmax(prediccionDeProbabilidadPorClase, dimension=1)\n",
    "\n",
    "# tf.Session es una clase para correr operaciones de tensorflow\n",
    "# Un objetivo de una sesion es encapsular el entorno en el cual los objectos (operaciones) son ejecutados y los objectos (Tensores) son evaluados.\n",
    "\n",
    "#inicializar las variables.\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#Entropia cruzada:\n",
    "entropiaCruzada = tf.nn.softmax_cross_entropy_with_logits(logits=capaTotalmenteConectada2,labels=tensorDeClases)\n",
    "perdidaTotalDeErrorEnClasificacion = tf.reduce_mean(entropiaCruzada)\n",
    "optimizador = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(perdidaTotalDeErrorEnClasificacion)\n",
    "correccionDePrediccion = tf.equal(prediccionDeProbabilidadPorClaseAplanada, tensorDeClasesAplanado)\n",
    "exactitudDelModelo = tf.reduce_mean(tf.cast(correccionDePrediccion, tf.float32))\n",
    "\n",
    "#inicializar las variables.\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<font color='red'>**Jupyter Kernel terminated:**</font> This might be caused by running out of memory or hitting a bug in some library (e.g., forking too many processes, trying to access invalid memory, etc.). Consider restarting or upgrading your project or running the relevant code directly in a terminal to track down the cause, as [explained here](https://github.com/sagemathinc/cocalc/wiki/KernelTerminated)."
      ]
     },
     "execution_count": 0,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mostrarProgreso(epoca, feed_dict_train, feed_dict_validate, perdidaDeValidacion):\n",
    "    exactitudDeEntrenamiento = session.run(exactitudDelModelo, feed_dict=feed_dict_train)\n",
    "    exactitudDeValidacion = session.run(exactitudDelModelo, feed_dict=feed_dict_validate)\n",
    "    msg = \"Training epoca {0} --- Exactitud del entranamiento: {1:>6.1%}, Exactitud de validacion: {2:>6.1%},  perida de validacion: {3:.3f}\"\n",
    "    print(msg.format(epoca + 1, exactitudDeEntrenamiento, exactitudDeValidacion, perdidaDeValidacion))\n",
    "\n",
    "recuentoIteraciones = 0\n",
    "\n",
    "\"\"\" batch-size (tamaño del lote por iteracion), cuando se entrena una red no se  alimenta con todo el conjunto de datos, se hace por medio de iteracion y cada iteracion tiene un tamaño, frecuentemente es 16 o 32\"\"\"\n",
    "\n",
    "tamanoLotePorIteracion = 4\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def entrenarModelo(totalIteraciones):\n",
    "    print(\"---------------- FUNCION DE ENTRENAMIENTO  ------------------\")\n",
    "    print(\"numero de imagenes para entrenamiento \"+str(data.train.num_examples))\n",
    "\n",
    "    global recuentoIteraciones\n",
    "    for iteracion in range(recuentoIteraciones,recuentoIteraciones + totalIteraciones):\n",
    "        print(\"-- iteracion # \"+str(iteracion+1))\n",
    "        x_batch, y_true_batch, _, cls_batch = data.train.siguienteLote(tamanoLotePorIteracion)\n",
    "        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.siguienteLote(tamanoLotePorIteracion)\n",
    "\n",
    "        feed_dict_tr = {x: x_batch,tensorDeClases: y_true_batch}\n",
    "        feed_dict_val = {x: x_valid_batch,tensorDeClases: y_valid_batch}\n",
    "        session.run(optimizador, feed_dict=feed_dict_tr)\n",
    "\n",
    "        if iteracion % int(data.train.num_examples/tamanoLotePorIteracion) == 0:\n",
    "            print(\"mostrar epoca \"+str(int(data.train.num_examples/tamanoLotePorIteracion)))\n",
    "            perdidadDeValidacion = session.run(perdidaTotalDeErrorEnClasificacion, feed_dict=feed_dict_val)\n",
    "\n",
    "            \"\"\" epoca (epoch) una epoca contiene un conjunto de iteracion que alimentan el modelo \"\"\"\n",
    "            epoca = int(iteracion / int(data.train.num_examples/tamanoLotePorIteracion))\n",
    "\n",
    "            mostrarProgreso(epoca, feed_dict_tr, feed_dict_val, perdidadDeValidacion)\n",
    "            \"\"\"saver.save(session, 'dogs-cats-model')\"\"\"\n",
    "\n",
    "    recuentoIteraciones += totalIteraciones\n",
    "\n",
    "entrenarModelo(totalIteraciones=6)\n",
    "print(\"end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}